{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from module import gen, dis, enc, random_z, kl, z2img\n",
    "from util import *\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "class BicycleGAN():\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        z_dim = args['z_dim']\n",
    "        im_size = args['im_size']\n",
    "        achannel_num = args['channel_num']\n",
    "        channel_num = args['channel_num']\n",
    "        lambda_kl = args['lambda_kl']\n",
    "        lambda_z = args['lambda_z']\n",
    "        lambda_l1 = args['lambda_l1']\n",
    "        layer_num = args['layer_num']\n",
    "        first_depth = args['first_depth']\n",
    "\n",
    "        self.A = tf.placeholder(tf.float32, [None, im_size, im_size, achannel_num], name='A')\n",
    "        self.B = tf.placeholder(tf.float32, [None, im_size, im_size, channel_num], name='B')\n",
    "        batch_size = tf.shape(self.A)[0] \n",
    "        \n",
    "        half_size = batch_size//2\n",
    "        self.A_encoded = self.A[:half_size]\n",
    "        self.A_random = self.A[half_size:]\n",
    "        self.B_encoded = self.B[:half_size]\n",
    "        self.B_random = self.B[half_size]\n",
    "        \n",
    "    \n",
    "        #################\n",
    "        #Part Of cLR-GAN#\n",
    "        #################\n",
    "        \n",
    "        # Fake Target B\n",
    "        r_size = tf.shape(self.A_random)[0]\n",
    "        z = random_z(r_size, z_dim)\n",
    "        self.B_ = gen(self.A, z, layer_num, first_depth, channel_num, False)\n",
    "        #print(self.B_.get_shape().as_list())\n",
    "\n",
    "\n",
    "        # Estimate laten z\n",
    "        mu, logvar = enc(self.B_, z_dim, reuse=False)\n",
    "\n",
    "        # Discriminator outs\n",
    "        dis_real = dis(tf.concat([self.A, self.B], -1), reuse=False)\n",
    "        dis_fake = dis(tf.concat([self.A, self.B_], -1), reuse=True)\n",
    "\n",
    "        # Losses\n",
    "        laten = tf.reduce_mean(tf.abs(mu - z)) * lambda_z\n",
    "        clr_g_loss = tf.reduce_mean(tf.ones_like(dis_fake) - dis_fake)\n",
    "        clr_d_loss = tf.reduce_mean(tf.ones_like(dis_real) - dis_real) + tf.reduce_mean(dis_fake)\n",
    "        \n",
    "        ##################\n",
    "        #Part Of cVAE-GAN#\n",
    "        ##################\n",
    "\n",
    "        # Estimate laten z\n",
    "        mu, logvar = enc(self.B, z_dim, reuse=True)\n",
    "        std = tf.log(logvar*.5 + 1e-16)\n",
    "        eps = random_z(half_size, z_dim) \n",
    "        z = eps*(std) + mu\n",
    "\n",
    "        # Fake Trarget B\n",
    "        B_ = gen(self.A, z, layer_num, first_depth, channel_num, True)\n",
    "\n",
    "        # Discriminator outs\n",
    "        dis_real = dis(tf.concat([self.A, self.B_], -1), reuse=True)\n",
    "        dis_fake = dis(tf.concat([self.A, B_], -1), reuse=True)\n",
    "\n",
    "        # Losses\n",
    "        l1 = tf.reduce_mean(tf.abs(self.B - B_)) * lambda_l1\n",
    "        kl_ = kl(mu, logvar) * lambda_kl\n",
    "        vae_g_loss = tf.reduce_mean(tf.ones_like(dis_fake) - dis_fake) + l1 + kl_ \n",
    "        vae_d_loss = tf.reduce_mean(tf.ones_like(dis_real) - dis_real) + tf.reduce_mean(dis_fake)\n",
    "           \n",
    "        ##########\n",
    "        # Hybrid #\n",
    "        ##########\n",
    "\n",
    "        self.e_loss = clr_g_loss + vae_g_loss\n",
    "        self.d_loss = clr_d_loss + vae_d_loss\n",
    "        self.g_loss = self.e_loss + laten\n",
    "\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        self.g_var = [var for var in trainable_vars if 'g' in var.name]\n",
    "        self.d_var = [var for var in trainable_vars if 'd' in var.name]\n",
    "        self.e_var = [var for var in trainable_vars if 'e' in var.name]\n",
    "\n",
    "        config = tf.ConfigProto(\n",
    "            gpu_options=tf.GPUOptions(\n",
    "                visible_device_list=\"0\",\n",
    "                allow_growth=True\n",
    "            )\n",
    "        )\n",
    "        self.sess = tf.Session(config=config)    \n",
    "\n",
    "    def fit(self, epochs, generator, lr, log_interval=100):\n",
    "        optim_g = tf.train.AdamOptimizer(lr).minimize(self.g_loss, var_list=self.g_var)\n",
    "        optim_e = tf.train.AdamOptimizer(lr).minimize(self.e_loss, var_list=self.e_var)\n",
    "        optim_d = tf.train.AdamOptimizer(lr).minimize(self.d_loss, var_list=self.d_var)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for i, (epoch, x, y) in enumerate(generator()):\n",
    "            fedd_dict = {\n",
    "                self.A: x,\n",
    "                self.B: y\n",
    "            }\n",
    "            \n",
    "            g_loss,_ = self.sess.run([self.g_loss, optim_g], feed_dict=feed_dict)\n",
    "            d_loss,_ = self.sess.run([self.d_loss, optim_d], feed_dict=feed_dict)\n",
    "            _ = self.sess.run(optim_e, feed_dict=feed_dict)\n",
    "            \n",
    "            if i % log_interval ==0:\n",
    "                print('epoch:', epoch, '\\titeration:' , i, '\\tg_loss:', g_loss, '\\td_loss', d_loss)\n",
    "\n",
    "            if i % 300 == 0:\n",
    "                y = self.sess.run(self.B_, feed_dict={self.A: x})\n",
    "                x = np.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "                \n",
    "                for j in range(x.shape[0]):\n",
    "                    plt.imswow(x[j])\n",
    "                    plt.show()\n",
    "                    plt.imshow(y[j])\n",
    "                    plt.show()\n",
    "                    \n",
    "            if epoch == epochs:\n",
    "                print('*******finished training!*******') \n",
    "                return\n",
    "\n",
    "    def pridict(self, x):\n",
    "        pass\n",
    "\n",
    "    def save(self, save_path):\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        saver.save(self.sess, save_path)        \n",
    "\n",
    "    def restore(self, save_path):\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        saver.restore(self.sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load images\n",
      " now process 3513 th image\t|□□□□□□□　　| "
     ]
    }
   ],
   "source": [
    "x, y = load_data('./data/edges2shoes/train')\n",
    "#gen = generator(32, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'z_dim': 16, 'im_size':256, 'achannel_num':1, 'channel_num':3, 'lambda_kl':.01, 'lambda_z':.5, 'lambda_l1':10, 'layer_num':4, 'first_depth':64}\n",
    "model_ = BicycleGAN(args)\n",
    "model_.fit(2000, gen, .0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
